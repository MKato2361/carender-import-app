from __future__ import annotations

from datetime import datetime, date, time, timedelta, timezone
from typing import Any, Dict, List, Optional
import io
import os
import re
import unicodedata
import zipfile

import pandas as pd
import streamlit as st
from firebase_admin import firestore

# ç‰©ä»¶ãƒã‚¹ã‚¿é–¢é€£ï¼ˆtab6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†åˆ©ç”¨ï¼‰
from tabs.tab6_property_master import (
    MASTER_COLUMNS,
    BASIC_COLUMNS,
    load_sheet_as_df,
    _normalize_df,
)
from utils.helpers import safe_get

# è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
try:
    from utils.harigami_generator import (
        DEFAULT_TEMPLATE_MAP,
        extract_tags_from_description,
        build_replacements_from_event,
        generate_docx_from_template_like,
    )

    HARIGAMI_AVAILABLE = True
    HARIGAMI_IMPORT_ERROR: Optional[Exception] = None
except Exception as e:  # ImportError ã‚„ python-docx æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚‚ã¾ã¨ã‚ã¦æ‹¾ã†
    HARIGAMI_AVAILABLE = False
    HARIGAMI_IMPORT_ERROR = e

JST = timezone(timedelta(hours=9))

# [ç®¡ç†ç•ªå·: HK5-123] å¯¾å¿œ
ASSETNUM_PATTERN = re.compile(
    r"[ï¼»\[]?\s*ç®¡ç†ç•ªå·[ï¼š:]\s*([0-9A-Za-z\-]+)\s*[ï¼½\]]?"
)

# [ä½œæ¥­ã‚¿ã‚¤ãƒ—: ç‚¹æ¤œ] ãªã©
WORKTYPE_PATTERN = re.compile(
    r"\[ä½œæ¥­ã‚¿ã‚¤ãƒ—[ï¼š:]\s*(.*?)\]"
)


def extract_assetnum(text: str) -> str:
    """èª¬æ˜ or ã‚¿ã‚¤ãƒˆãƒ« ã‹ã‚‰ç®¡ç†ç•ªå·ã‚’æŠ½å‡º"""
    if not text:
        return ""
    s = unicodedata.normalize("NFKC", str(text))
    m = ASSETNUM_PATTERN.search(s)
    if not m:
        return ""
    return m.group(1).strip()


def extract_worktype(text: str) -> str:
    """èª¬æ˜ã‹ã‚‰ä½œæ¥­ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºï¼ˆãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰"""
    if not text:
        return ""
    s = unicodedata.normalize("NFKC", str(text))
    m = WORKTYPE_PATTERN.search(s)
    if not m:
        return ""
    return (m.group(1) or "").strip()


def to_utc_range_from_dates(d1: date, d2: date) -> tuple[str, str]:
    """JST ã®æ—¥ä»˜ç¯„å›² â†’ Calendar API ç”¨ UTC ISO æ–‡å­—åˆ—"""
    start_dt_utc = datetime.combine(d1, time.min, tzinfo=JST).astimezone(timezone.utc)
    end_dt_utc = datetime.combine(d2, time.max, tzinfo=JST).astimezone(timezone.utc)
    return start_dt_utc.isoformat(), end_dt_utc.isoformat()


def get_event_start_datetime(event: Dict[str, Any]) -> Optional[datetime]:
    """Google ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰é–‹å§‹æ—¥æ™‚ï¼ˆJSTï¼‰ã‚’å–å¾—"""
    start = event.get("start", {})
    # æ™‚é–“ä»˜ãäºˆå®š
    if "dateTime" in start:
        try:
            dt = pd.to_datetime(start["dateTime"])
            if dt.tzinfo is None:
                dt = dt.tz_localize(timezone.utc)
            dt = dt.astimezone(JST)
            return dt.to_pydatetime()
        except Exception:
            return None
    # çµ‚æ—¥äºˆå®š
    if "date" in start:
        try:
            d = date.fromisoformat(start["date"])
            return datetime.combine(d, time.min, tzinfo=JST)
        except Exception:
            return None
    return None


def fetch_events_in_range(
    service: Any,
    calendar_id: str,
    start_date: date,
    end_date: date,
) -> List[Dict[str, Any]]:
    """æŒ‡å®šæœŸé–“ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰å–å¾—"""
    if not service:
        return []

    time_min, time_max = to_utc_range_from_dates(start_date, end_date)

    events: List[Dict[str, Any]] = []
    page_token: Optional[str] = None

    while True:
        resp = (
            service.events()
            .list(
                calendarId=calendar_id,
                timeMin=time_min,
                timeMax=time_max,
                maxResults=2500,
                singleEvents=True,
                orderBy="startTime",
                pageToken=page_token,
            )
            .execute()
        )
        items = resp.get("items", [])
        events.extend(items)
        page_token = resp.get("nextPageToken")
        if not page_token:
            break

    return events


def get_property_master_spreadsheet_id(current_user_email: Optional[str]) -> str:
    """Firestore user_settings ã‹ã‚‰ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ Spreadsheet ID ã‚’å–å¾—"""
    if not current_user_email:
        return ""
    try:
        db = firestore.client()
        doc = db.collection("user_settings").document(current_user_email).get()
        if not doc.exists:
            return ""
        data = doc.to_dict() or {}
        return data.get("property_master_spreadsheet_id") or ""
    except Exception as e:
        st.warning(f"ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return ""


def load_property_master_view(
    sheets_service: Any,
    spreadsheet_id: str,
    basic_sheet_title: str = "ç‰©ä»¶åŸºæœ¬æƒ…å ±",
    master_sheet_title: str = "ç‰©ä»¶ãƒã‚¹ã‚¿",
) -> pd.DataFrame:
    """
    ç‰©ä»¶åŸºæœ¬æƒ…å ± ï¼‹ ç‰©ä»¶ãƒã‚¹ã‚¿ ã‚’ç®¡ç†ç•ªå·ã§ãƒãƒ¼ã‚¸ã—ãŸãƒ“ãƒ¥ãƒ¼ DF ã‚’è¿”ã™
    """
    if not sheets_service or not spreadsheet_id:
        return pd.DataFrame()

    try:
        basic_df = load_sheet_as_df(
            sheets_service,
            spreadsheet_id,
            basic_sheet_title,
            BASIC_COLUMNS,
        )
        master_df = load_sheet_as_df(
            sheets_service,
            spreadsheet_id,
            master_sheet_title,
            MASTER_COLUMNS,
        )
    except Exception as e:
        st.error(f"ç‰©ä»¶ãƒã‚¹ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

    basic_df = _normalize_df(basic_df, BASIC_COLUMNS)
    master_df = _normalize_df(master_df, MASTER_COLUMNS)

    if master_df.empty:
        merged = basic_df.copy()
        for col in MASTER_COLUMNS:
            if col not in merged.columns:
                merged[col] = ""
        return merged

    merged = master_df.merge(
        basic_df[["ç®¡ç†ç•ªå·", "ç‰©ä»¶å", "ä½æ‰€", "çª“å£ä¼šç¤¾"]],
        on="ç®¡ç†ç•ªå·",
        how="left",
    )

    return merged


def _display_value(val: Any) -> str:
    """nan / None / ç©ºæ–‡å­— ã‚’ '-' ã«æƒãˆã‚‹"""
    if val is None:
        return "-"
    s = str(val).strip()
    if not s or s.lower() in ("nan", "none"):
        return "-"
    return s


def _build_safe_title(when: str, mgmt: str, name: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
    parts = []
    if when:
        parts.append(when)
    if mgmt:
        parts.append(mgmt)
    if name:
        parts.append(name)
    if not parts:
        return "harigami"
    return "_".join(parts)


# ============================================================
# ãƒ¡ã‚¤ãƒ³ï¼šè²¼ã‚Šç´™è‡ªå‹•ä½œæˆã‚¿ãƒ–
# ============================================================

def render_tab8_notice_fax(
    service: Any,
    editable_calendar_options: Dict[str, str],
    sheets_service: Any = None,
    current_user_email: Optional[str] = None,
    **kwargs,
) -> None:
    """
    è²¼ã‚Šç´™è‡ªå‹•ç”Ÿæˆã‚¿ãƒ–

    - æŒ‡å®šæœŸé–“ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
    - ç‰©ä»¶ãƒã‚¹ã‚¿ã¨ç®¡ç†ç•ªå·ã§çªåˆï¼ˆä»»æ„ï¼‰
    - ã€Œè²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥=è‡ªç¤¾ã€ã®ã¿å¯¾è±¡ã¨ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
      ã¾ãŸã¯
      ç‰©ä»¶ãƒã‚¹ã‚¿ã‚’ä½¿ã‚ãšç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¸€è¦§è¡¨ç¤ºã—ã¦æ‰‹å‹•é¸æŠã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
    - ä½œæ¥­ã‚¿ã‚¤ãƒ— â†’ DEFAULT_TEMPLATE_MAP ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    - Word è²¼ã‚Šç´™ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã€ZIP ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """
    st.subheader("ğŸ“„ è²¼ã‚Šç´™è‡ªå‹•ä½œæˆ")

    # harigami ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä½¿ãˆãªã„å ´åˆ
    if not HARIGAMI_AVAILABLE:
        st.error(
            "è²¼ã‚Šç´™ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆutils.harigami_generatorï¼‰ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
            "ãƒ»requirements.txt ã« `python-docx` ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹\n"
            "ãƒ»`utils/harigami_generator.py` ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹\n"
            "ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"
            f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {HARIGAMI_IMPORT_ERROR}"
        )
        return

    if not service or not editable_calendar_options:
        st.warning("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¿ãƒ–1ã€œ2ã§èªè¨¼ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        return

    # ç‰©ä»¶ãƒã‚¹ã‚¿ Spreadsheet ID
    spreadsheet_id = get_property_master_spreadsheet_id(current_user_email)

    pm_view_df: pd.DataFrame = pd.DataFrame()
    has_master = False

    if sheets_service is not None and spreadsheet_id:
        # ç‰©ä»¶ãƒã‚¹ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯èª­ã¿è¾¼ã‚“ã§ãŠãï¼ˆä»»æ„åˆ©ç”¨ï¼‰
        st.markdown(
            f"ç‰©ä»¶ãƒã‚¹ã‚¿ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: "
            f"[ã“ã¡ã‚‰ã‚’é–‹ã](https://docs.google.com/spreadsheets/d/{spreadsheet_id})"
        )

        pm_view_df = load_property_master_view(
            sheets_service,
            spreadsheet_id,
            basic_sheet_title="ç‰©ä»¶åŸºæœ¬æƒ…å ±",
            master_sheet_title="ç‰©ä»¶ãƒã‚¹ã‚¿",
        )

        if pm_view_df is not None and not pm_view_df.empty:
            has_master = True
            col_flag = "è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥"
            if col_flag in pm_view_df.columns:
                flag_series = pm_view_df[col_flag].fillna("").astype(str).str.strip()
                cnt_jisha = (flag_series == "è‡ªç¤¾").sum()
                st.caption(
                    f"ç‰©ä»¶ãƒã‚¹ã‚¿ç™»éŒ²ä»¶æ•°: {len(pm_view_df)} ä»¶ / "
                    f"è²¼ã‚Šç´™å¯¾è±¡ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥=è‡ªç¤¾ï¼‰: {cnt_jisha} ä»¶"
                )
            else:
                st.caption(f"ç‰©ä»¶ãƒã‚¹ã‚¿ç™»éŒ²ä»¶æ•°: {len(pm_view_df)} ä»¶")
        else:
            st.warning(
                "ç‰©ä»¶ãƒã‚¹ã‚¿ï¼ˆã¾ãŸã¯ç‰©ä»¶åŸºæœ¬æƒ…å ±ï¼‰ãŒç©ºã€ã‚‚ã—ãã¯èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                "å¿…è¦ã«å¿œã˜ã¦ã‚¿ãƒ–ã€ç‰©ä»¶ãƒã‚¹ã‚¿ç®¡ç†ã€ã§ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚"
            )
    else:
        # ç‰©ä»¶ãƒã‚¹ã‚¿ãŒç„¡ãã¦ã‚‚ã€ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰ç›´æ¥ä½œæˆã§ãã‚‹ãƒ¢ãƒ¼ãƒ‰ã‚’æ¡ˆå†…
        st.info(
            "ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒæœªè¨­å®šã€ã¾ãŸã¯ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n"
            "ã“ã®çŠ¶æ…‹ã§ã‚‚ã€ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã®ä¸€è¦§ã‹ã‚‰é¸æŠã—ã¦è²¼ã‚Šç´™ã‚’ä½œæˆã§ãã¾ã™ã€‚"
        )

    # è²¼ã‚Šç´™å¯¾è±¡ã®æ±ºã‚æ–¹ï¼ˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    if has_master:
        mode_options = [
            "ç‰©ä»¶ãƒã‚¹ã‚¿ã®ã€è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥=è‡ªç¤¾ã€ã®ã¿å¯¾è±¡ã«ã™ã‚‹",
            "ç‰©ä»¶ãƒã‚¹ã‚¿ã‚’ä½¿ã‚ãšã€ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã‚’ã™ã¹ã¦ä¸€è¦§è¡¨ç¤ºã—ã¦æ‰‹å‹•é¸æŠã™ã‚‹",
        ]
        mode = st.radio(
            "è²¼ã‚Šç´™å¯¾è±¡ã®é¸ã³æ–¹",
            mode_options,
            index=0,
            key="notice_fax_mode",
        )
        use_master_filter = (mode == mode_options[0])
    else:
        st.info(
            "ç¾åœ¨ã€ç‰©ä»¶ãƒã‚¹ã‚¿ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€"
            "ã€ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã‚’ã™ã¹ã¦ä¸€è¦§è¡¨ç¤ºã—ã¦æ‰‹å‹•é¸æŠã™ã‚‹ã€ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚"
        )
        use_master_filter = False

    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é¸æŠ
    cal_names = list(editable_calendar_options.keys())
    default_cal = cal_names[0] if cal_names else None
    calendar_name = st.selectbox(
        "å¯¾è±¡ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼",
        cal_names,
        index=(cal_names.index(default_cal) if default_cal in cal_names else 0),
        key="notice_fax_calendar",
    )
    calendar_id = editable_calendar_options.get(calendar_name)

    # æœŸé–“æŒ‡å®š
    today = date.today()
    col_d1, col_d2 = st.columns(2)
    with col_d1:
        start_date = st.date_input("å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®é–‹å§‹æ—¥", value=today, key="notice_fax_start_date")
    with col_d2:
        end_date = st.date_input("å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®çµ‚äº†æ—¥", value=today + timedelta(days=60), key="notice_fax_end_date")

    if start_date > end_date:
        st.error("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ä»¥å‰ã®æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        return

    # ã‚¤ãƒ™ãƒ³ãƒˆå–å¾—ãƒœã‚¿ãƒ³
    fetch_btn = st.button("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã—ã€è²¼ã‚Šç´™å€™è£œã‚’ä½œæˆã™ã‚‹", type="primary")

    if fetch_btn:
        with st.spinner("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ä¸­..."):
            events = fetch_events_in_range(service, calendar_id, start_date, end_date)

        st.write(f"å–å¾—ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆä»¶æ•°: {len(events)} ä»¶")

        # ç‰©ä»¶ãƒã‚¹ã‚¿ã‚’ç®¡ç†ç•ªå·ã§å¼•ã‘ã‚‹ã‚ˆã†ã«ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
        pm_idx = None
        if isinstance(pm_view_df, pd.DataFrame) and not pm_view_df.empty and "ç®¡ç†ç•ªå·" in pm_view_df.columns:
            pm_idx = pm_view_df.set_index("ç®¡ç†ç•ªå·")

        candidates: List[Dict[str, Any]] = []
        events_by_id: Dict[str, Dict[str, Any]] = {}

        for ev in events:
            desc = safe_get(ev, "description") or ""
            summary = safe_get(ev, "summary") or ""

            # ç®¡ç†ç•ªå·æŠ½å‡ºï¼ˆèª¬æ˜ or ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
            mgmt = extract_assetnum(desc) or extract_assetnum(summary)
            if not mgmt:
                # ç®¡ç†ç•ªå·ãŒå–ã‚Œãªã„ã‚¤ãƒ™ãƒ³ãƒˆã¯è²¼ã‚Šç´™å¯¾è±¡å¤–
                continue
            mgmt_norm = mgmt.strip()

            pm_row = None
            flag_val = ""
            pm_name = ""
            pm_remark = ""

            if pm_idx is not None and mgmt_norm in pm_idx.index:
                pm_row = pm_idx.loc[mgmt_norm]
                flag_val = str(pm_row.get("è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥", "")).strip()
                pm_name = _display_value(pm_row.get("ç‰©ä»¶å", ""))
                pm_remark = _display_value(pm_row.get("å‚™è€ƒ", ""))

            # ç‰©ä»¶ãƒã‚¹ã‚¿ã®ã€Œè²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥=è‡ªç¤¾ã€ã§çµã‚Šè¾¼ã‚€ãƒ¢ãƒ¼ãƒ‰
            if use_master_filter:
                # ç‰©ä»¶ãƒã‚¹ã‚¿ã«å­˜åœ¨ã—ãªã„ or ãƒ•ãƒ©ã‚°ãŒè‡ªç¤¾ä»¥å¤– â†’ å¯¾è±¡å¤–
                if pm_row is None:
                    continue
                if flag_val != "è‡ªç¤¾":
                    continue

            start_dt = get_event_start_datetime(ev)
            start_date_val = start_dt.date() if start_dt else None
            date_str = start_date_val.strftime("%Y-%m-%d") if start_date_val else ""
            time_str = start_dt.strftime("%H:%M") if start_dt and "dateTime" in (ev.get("start") or {}) else ""

            work_type = extract_worktype(desc)
            if not work_type:
                work_type = "default"
            template_file = DEFAULT_TEMPLATE_MAP.get(work_type, DEFAULT_TEMPLATE_MAP.get("default"))

            # ä¸€è¦§ã«è¡¨ç¤ºã™ã‚‹ç‰©ä»¶åã¯
            # ç‰©ä»¶ãƒã‚¹ã‚¿ > ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ« > ç®¡ç†ç•ªå· ã®å„ªå…ˆé †ä½ã§æ±ºå®š
            name_for_list = _display_value(pm_name or summary or mgmt_norm or "")
            remark_for_list = _display_value(pm_remark or "")

            candidates.append(
                {
                    "ä½œæˆ": True,
                    "event_id": ev.get("id") or "",
                    "ç®¡ç†ç•ªå·": mgmt_norm,
                    "ç‰©ä»¶å": name_for_list,
                    "äºˆå®šæ—¥": date_str,
                    "äºˆå®šæ™‚é–“": time_str,
                    "ä½œæ¥­ã‚¿ã‚¤ãƒ—": work_type,
                    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«": template_file,
                    "è²¼ã‚Šç´™ãƒ•ãƒ©ã‚°": flag_val,
                    "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«": _display_value(summary),
                    "å‚™è€ƒ": remark_for_list,
                }
            )

            ev_id = ev.get("id")
            if ev_id:
                events_by_id[ev_id] = ev

        if not candidates:
            if use_master_filter:
                st.info(
                    "ç‰©ä»¶ãƒã‚¹ã‚¿ã®ã€è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥=è‡ªç¤¾ã€ã«è©²å½“ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                    "å¿…è¦ã«å¿œã˜ã¦ã€ãƒ¢ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¦ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¸€è¦§è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚"
                )
            else:
                st.info("ç®¡ç†ç•ªå·ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.session_state.pop("notice_fax_candidates_df", None)
            st.session_state.pop("notice_fax_events_by_id", None)
            st.session_state.pop("notice_fax_pm_view_df", None)
        else:
            cand_df = pd.DataFrame(candidates).fillna("")
            cand_df["ä½œæˆ"] = cand_df["ä½œæˆ"].astype(bool)

            st.session_state["notice_fax_candidates_df"] = cand_df
            st.session_state["notice_fax_events_by_id"] = events_by_id
            st.session_state["notice_fax_pm_view_df"] = pm_view_df

            st.success(
                f"è²¼ã‚Šç´™å€™è£œ {len(candidates)} ä»¶ã‚’ä½œæˆã—ã¾ã—ãŸã€‚\n"
                "ã“ã®ä¸‹ã§å†…å®¹ã‚’ç¢ºèªã—ã€ä½œæˆå¯¾è±¡ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"
            )

    # ã“ã“ã‹ã‚‰ã¯æ—¢ã«å€™è£œãŒã‚ã‚‹å ´åˆã®è¡¨ç¤º
    cand_df: Optional[pd.DataFrame] = st.session_state.get("notice_fax_candidates_df")
    events_by_id: Dict[str, Dict[str, Any]] = st.session_state.get("notice_fax_events_by_id", {})
    pm_view_df = st.session_state.get("notice_fax_pm_view_df", pm_view_df)

    if cand_df is None or cand_df.empty:
        return

    st.markdown("### è²¼ã‚Šç´™ä½œæˆå€™è£œä¸€è¦§")
    st.caption("â€»ã€ä½œæˆã€ãƒã‚§ãƒƒã‚¯ãŒ ON ã®è¡Œã ã‘ãŒè²¼ã‚Šç´™ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ OFF ã«ã—ã¦ãã ã•ã„ã€‚")

    display_cols = [
        "ä½œæˆ",
        "ç®¡ç†ç•ªå·",
        "ç‰©ä»¶å",
        "äºˆå®šæ—¥",
        "äºˆå®šæ™‚é–“",
        "ä½œæ¥­ã‚¿ã‚¤ãƒ—",
        "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«",
        "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«",
        "å‚™è€ƒ",
    ]

    for col in display_cols:
        if col not in cand_df.columns:
            cand_df[col] = True if col == "ä½œæˆ" else ""

    disp_df = cand_df[display_cols].copy()
    for col in disp_df.columns:
        if col == "ä½œæˆ":
            disp_df[col] = disp_df[col].astype(bool)
        else:
            disp_df[col] = (
                disp_df[col]
                .fillna("")
                .astype(str)
                .replace({"nan": "-", "NaN": "-", "None": "-"})
            )

    edit_df = st.data_editor(
        disp_df,
        num_rows="fixed",
        use_container_width=True,
        hide_index=True,
        column_config={
            "ä½œæˆ": st.column_config.CheckboxColumn("ä½œæˆ"),
            "ç®¡ç†ç•ªå·": st.column_config.TextColumn("ç®¡ç†ç•ªå·", disabled=True),
            "ç‰©ä»¶å": st.column_config.TextColumn("ç‰©ä»¶å", disabled=True),
            "äºˆå®šæ—¥": st.column_config.TextColumn("äºˆå®šæ—¥", disabled=True),
            "äºˆå®šæ™‚é–“": st.column_config.TextColumn("äºˆå®šæ™‚é–“", disabled=True),
            "ä½œæ¥­ã‚¿ã‚¤ãƒ—": st.column_config.TextColumn("ä½œæ¥­ã‚¿ã‚¤ãƒ—", disabled=True),
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«": st.column_config.TextColumn("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«", disabled=True),
            "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«": st.column_config.TextColumn("ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«", disabled=True),
            "å‚™è€ƒ": st.column_config.TextColumn("å‚™è€ƒ", disabled=True),
        },
        key="notice_fax_editor",
    )

    cand_df["ä½œæˆ"] = edit_df["ä½œæˆ"].values
    st.session_state["notice_fax_candidates_df"] = cand_df

    generate_btn = st.button("âœ… é¸æŠã•ã‚ŒãŸè¡Œã®è²¼ã‚Šç´™ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã€ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹", type="primary")

    if not generate_btn:
        return

    target_df = cand_df[cand_df["ä½œæˆ"] == True].copy()
    if target_df.empty:
        st.warning("ã€ä½œæˆã€ã«ãƒã‚§ãƒƒã‚¯ãŒå…¥ã£ã¦ã„ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    if not events_by_id:
        st.error("å†…éƒ¨ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†åº¦ã€è²¼ã‚Šç´™å€™è£œã‚’ä½œæˆã€ãƒœã‚¿ãƒ³ã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
        return

    # ç‰©ä»¶ãƒã‚¹ã‚¿ï¼ˆã‚ã‚Œã°ï¼‰ã‚’ç®¡ç†ç•ªå·ã§å‚ç…§
    pm_idx = None
    if isinstance(pm_view_df, pd.DataFrame) and not pm_view_df.empty and "ç®¡ç†ç•ªå·" in pm_view_df.columns:
        pm_idx = pm_view_df.set_index("ç®¡ç†ç•ªå·")

    outputs: List[tuple[str, bytes]] = []
    errors: List[str] = []

    with st.spinner("è²¼ã‚Šç´™ï¼ˆWordï¼‰ã‚’ç”Ÿæˆä¸­..."):
        for _, row in target_df.iterrows():
            event_id = row.get("event_id")
            mgmt = row.get("ç®¡ç†ç•ªå·")
            if not event_id or not mgmt:
                continue

            ev = events_by_id.get(event_id)
            if ev is None:
                continue

            pm_row = None
            if pm_idx is not None and mgmt in pm_idx.index:
                pm_row = pm_idx.loc[mgmt]

            desc = safe_get(ev, "description") or ""
            summary = safe_get(ev, "summary") or ""

            tags = extract_tags_from_description(desc or "")
            # description ã«ç®¡ç†ç•ªå·ã‚¿ã‚°ãŒå…¥ã£ã¦ã„ãªã„å ´åˆã‚‚ã‚ã‚‹ã®ã§è£œå®Œ
            if "ASSETNUM" not in tags and mgmt:
                tags["ASSETNUM"] = mgmt

            work_type = extract_worktype(desc)
            if not work_type:
                work_type = "default"
            template_file = DEFAULT_TEMPLATE_MAP.get(work_type, DEFAULT_TEMPLATE_MAP.get("default"))
            template_path = os.path.join("templates", template_file)

            start_dt = get_event_start_datetime(ev)
            when_str = ""
            if start_dt:
                d = start_dt.date()
                when_str = d.strftime("%Y-%m-%d")

            # NAME ã¯ç‰©ä»¶ãƒã‚¹ã‚¿ã®ç‰©ä»¶åã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã°ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«ï¼ç®¡ç†ç•ªå·ã‚’ä½¿ã†
            if pm_row is not None:
                name_for_doc = str(pm_row.get("ç‰©ä»¶å") or summary or mgmt or "").strip()
            else:
                name_for_doc = str(summary or mgmt or "").strip()

            replacements = build_replacements_from_event(ev, name_for_doc, tags)
            safe_title = _build_safe_title(when_str, mgmt, name_for_doc)

            try:
                out_name, content = generate_docx_from_template_like(
                    template_path,
                    replacements,
                    safe_title,
                )
                outputs.append((out_name, content))
            except Exception as e:
                errors.append(f"{mgmt}: {e}")

    if not outputs:
        st.error("è²¼ã‚Šç´™ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®ã‚„æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        if errors:
            st.warning(f"ã‚¨ãƒ©ãƒ¼ä¾‹: {errors[0]}")
        return

    mem_zip = io.BytesIO()
    with zipfile.ZipFile(mem_zip, "w", zipfile.ZIP_DEFLATED) as zf:
        used_names = set()
        for fname, content in outputs:
            base_name = fname or "harigami.docx"
            name = base_name
            idx = 1
            while name in used_names:
                root, ext = os.path.splitext(base_name)
                name = f"{root}_{idx}{ext}"
                idx += 1
            used_names.add(name)
            zf.writestr(name, content)

    mem_zip.seek(0)
    zip_filename = f"harigami_{datetime.now().strftime('%Y%m%d')}.zip"

    st.download_button(
        "ğŸ“¦ è²¼ã‚Šç´™ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=mem_zip.getvalue(),
        file_name=zip_filename,
        mime="application/zip",
    )

    if errors:
        st.warning(f"ä¸€éƒ¨ã®è²¼ã‚Šç´™ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{len(errors)} ä»¶ï¼‰ã€‚å…ˆé ­ã®ã‚¨ãƒ©ãƒ¼: {errors[0]}")
