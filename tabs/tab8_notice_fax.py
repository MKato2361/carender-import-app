from __future__ import annotations

from datetime import datetime, date, time, timedelta, timezone
from typing import Any, Dict, List, Optional
import io
import os
import re
import unicodedata
import zipfile

import pandas as pd
import streamlit as st
from firebase_admin import firestore

# ç‰©ä»¶ãƒã‚¹ã‚¿é–¢é€£ï¼ˆtab6 ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†åˆ©ç”¨ï¼‰
from tabs.tab6_property_master import (
    MASTER_COLUMNS,
    BASIC_COLUMNS,
    load_sheet_as_df,
    _normalize_df,
)
from utils.helpers import safe_get

# è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
try:
    from utils.harigami_generator import (
        DEFAULT_TEMPLATE_MAP,
        extract_tags_from_description,
        build_replacements_from_event,
        generate_docx_from_template_like,
    )

    HARIGAMI_AVAILABLE = True
    HARIGAMI_IMPORT_ERROR: Optional[Exception] = None
except Exception as e:  # ImportError ã‚„ python-docx æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚‚ã¾ã¨ã‚ã¦æ‹¾ã†
    HARIGAMI_AVAILABLE = False
    HARIGAMI_IMPORT_ERROR = e

JST = timezone(timedelta(hours=9))

# [ç®¡ç†ç•ªå·: HK5-123] å¯¾å¿œ
ASSETNUM_PATTERN = re.compile(
    r"[ï¼»\[]?\s*ç®¡ç†ç•ªå·[ï¼š:]\s*([0-9A-Za-z\-]+)\s*[ï¼½\]]?"
)

# [ä½œæ¥­ã‚¿ã‚¤ãƒ—: ç‚¹æ¤œ] ãªã©
WORKTYPE_PATTERN = re.compile(
    r"\[ä½œæ¥­ã‚¿ã‚¤ãƒ—[ï¼š:]\s*(.*?)\]"
)


def extract_assetnum(text: str) -> str:
    """èª¬æ˜ or ã‚¿ã‚¤ãƒˆãƒ« ã‹ã‚‰ç®¡ç†ç•ªå·ã‚’æŠ½å‡º"""
    if not text:
        return ""
    s = unicodedata.normalize("NFKC", str(text))
    m = ASSETNUM_PATTERN.search(s)
    if not m:
        return ""
    return m.group(1).strip()


def extract_worktype(text: str) -> str:
    """èª¬æ˜ã‹ã‚‰ä½œæ¥­ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºï¼ˆãªã‘ã‚Œã°ç©ºæ–‡å­—ï¼‰"""
    if not text:
        return ""
    s = unicodedata.normalize("NFKC", str(text))
    m = WORKTYPE_PATTERN.search(s)
    if not m:
        return ""
    return (m.group(1) or "").strip()


def to_utc_range_from_dates(d1: date, d2: date) -> tuple[str, str]:
    """JST ã®æ—¥ä»˜ç¯„å›² â†’ Calendar API ç”¨ UTC ISO æ–‡å­—åˆ—"""
    start_dt_utc = datetime.combine(d1, time.min, tzinfo=JST).astimezone(timezone.utc)
    end_dt_utc = datetime.combine(d2, time.max, tzinfo=JST).astimezone(timezone.utc)
    return start_dt_utc.isoformat(), end_dt_utc.isoformat()


def get_event_start_datetime(event: Dict[str, Any]) -> Optional[datetime]:
    """Google ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰é–‹å§‹æ—¥æ™‚ï¼ˆJSTï¼‰ã‚’å–å¾—"""
    start = event.get("start", {})
    # æ™‚é–“ä»˜ãäºˆå®š
    if "dateTime" in start:
        try:
            dt = pd.to_datetime(start["dateTime"])
            if dt.tzinfo is None:
                dt = dt.tz_localize(timezone.utc)
            dt = dt.astimezone(JST)
            return dt.to_pydatetime()
        except Exception:
            return None
    # çµ‚æ—¥äºˆå®š
    if "date" in start:
        try:
            d = date.fromisoformat(start["date"])
            return datetime.combine(d, time.min, tzinfo=JST)
        except Exception:
            return None
    return None


def fetch_events_in_range(
    service: Any,
    calendar_id: str,
    start_date: date,
    end_date: date,
) -> List[Dict[str, Any]]:
    """æŒ‡å®šæœŸé–“ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰å–å¾—"""
    if not service:
        return []

    time_min, time_max = to_utc_range_from_dates(start_date, end_date)

    events: List[Dict[str, Any]] = []
    page_token: Optional[str] = None

    while True:
        resp = (
            service.events()
            .list(
                calendarId=calendar_id,
                timeMin=time_min,
                timeMax=time_max,
                maxResults=2500,
                singleEvents=True,
                orderBy="startTime",
                pageToken=page_token,
            )
            .execute()
        )
        items = resp.get("items", [])
        events.extend(items)
        page_token = resp.get("nextPageToken")
        if not page_token:
            break

    return events


def get_property_master_spreadsheet_id(current_user_email: Optional[str]) -> str:
    """Firestore user_settings ã‹ã‚‰ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ Spreadsheet ID ã‚’å–å¾—"""
    if not current_user_email:
        return ""
    try:
        db = firestore.client()
        doc = db.collection("user_settings").document(current_user_email).get()
        if not doc.exists:
            return ""
        data = doc.to_dict() or {}
        return data.get("property_master_spreadsheet_id") or ""
    except Exception as e:
        st.warning(f"ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return ""


def load_property_master_view(
    sheets_service: Any,
    spreadsheet_id: str,
    basic_sheet_title: str = "ç‰©ä»¶åŸºæœ¬æƒ…å ±",
    master_sheet_title: str = "ç‰©ä»¶ãƒã‚¹ã‚¿",
) -> pd.DataFrame:
    """
    ç‰©ä»¶åŸºæœ¬æƒ…å ± ï¼‹ ç‰©ä»¶ãƒã‚¹ã‚¿ ã‚’ç®¡ç†ç•ªå·ã§ãƒãƒ¼ã‚¸ã—ãŸãƒ“ãƒ¥ãƒ¼ DF ã‚’è¿”ã™
    """
    if not sheets_service or not spreadsheet_id:
        return pd.DataFrame()

    try:
        basic_df = load_sheet_as_df(
            sheets_service,
            spreadsheet_id,
            basic_sheet_title,
            BASIC_COLUMNS,
        )
        master_df = load_sheet_as_df(
            sheets_service,
            spreadsheet_id,
            master_sheet_title,
            MASTER_COLUMNS,
        )
    except Exception as e:
        st.error(f"ç‰©ä»¶ãƒã‚¹ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

    basic_df = _normalize_df(basic_df, BASIC_COLUMNS)
    master_df = _normalize_df(master_df, MASTER_COLUMNS)

    if master_df.empty:
        merged = basic_df.copy()
        for col in MASTER_COLUMNS:
            if col not in merged.columns:
                merged[col] = ""
        return merged

    merged = master_df.merge(
        basic_df[["ç®¡ç†ç•ªå·", "ç‰©ä»¶å", "ä½æ‰€", "çª“å£ä¼šç¤¾"]],
        on="ç®¡ç†ç•ªå·",
        how="left",
    )

    return merged


def _display_value(val: Any) -> str:
    """nan / None / ç©ºæ–‡å­— ã‚’ '-' ã«æƒãˆã‚‹"""
    if val is None:
        return "-"
    s = str(val).strip()
    if not s or s.lower() in ("nan", "none"):
        return "-"
    return s


def _build_safe_title(when: str, mgmt: str, name: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ"""
    parts = []
    if when:
        parts.append(when)
    if mgmt:
        parts.append(mgmt)
    if name:
        parts.append(name)
    if not parts:
        return "harigami"
    return "_".join(parts)


# ============================================================
# ãƒ¡ã‚¤ãƒ³ï¼šè²¼ã‚Šç´™è‡ªå‹•ä½œæˆã‚¿ãƒ–
# ============================================================

def render_tab8_notice_fax(
    service: Any,
    editable_calendar_options: Dict[str, str],
    sheets_service: Any = None,
    current_user_email: Optional[str] = None,
    **kwargs,
) -> None:
    """
    è²¼ã‚Šç´™è‡ªå‹•ç”Ÿæˆã‚¿ãƒ–

    - æŒ‡å®šæœŸé–“ã®ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
    - ç‰©ä»¶ãƒã‚¹ã‚¿ã¨ç®¡ç†ç•ªå·ã§çªåˆ
    - ã€Œè²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥ã€ãŒã€Œè‡ªç¤¾ã€ã®ã‚‚ã®ã ã‘ã‚’å¯¾è±¡
    - ä½œæ¥­ã‚¿ã‚¤ãƒ— â†’ DEFAULT_TEMPLATE_MAP ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    - Word è²¼ã‚Šç´™ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã€ZIP ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """
    st.subheader("ğŸ“„ è²¼ã‚Šç´™è‡ªå‹•ä½œæˆ")

    # harigami ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä½¿ãˆãªã„å ´åˆ
    if not HARIGAMI_AVAILABLE:
        st.error(
            "è²¼ã‚Šç´™ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆutils.harigami_generatorï¼‰ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
            "ãƒ»requirements.txt ã« `python-docx` ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹\n"
            "ãƒ»`utils/harigami_generator.py` ãŒæ­£ã—ãé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹\n"
            "ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"
            f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {HARIGAMI_IMPORT_ERROR}"
        )
        return

    if not service or not editable_calendar_options:
        st.warning("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¿ãƒ–1ã€œ2ã§èªè¨¼ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        return

    # ç‰©ä»¶ãƒã‚¹ã‚¿ Spreadsheet ID
    spreadsheet_id = get_property_master_spreadsheet_id(current_user_email)
    if not spreadsheet_id:
        st.error(
            "ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n\n"
            "ã‚¿ãƒ–ã€ç‰©ä»¶ãƒã‚¹ã‚¿ç®¡ç†ã€ã§ç‰©ä»¶ãƒã‚¹ã‚¿ã‚’ä½œæˆãƒ»ä¿å­˜ã™ã‚‹ã¨ã€ã“ã®æ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚"
        )
        return

    st.markdown(
        f"ç‰©ä»¶ãƒã‚¹ã‚¿ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: "
        f"[ã“ã¡ã‚‰ã‚’é–‹ã](https://docs.google.com/spreadsheets/d/{spreadsheet_id})"
    )

    # ç‰©ä»¶ãƒã‚¹ã‚¿ãƒ“ãƒ¥ãƒ¼
    pm_view_df = load_property_master_view(
        sheets_service,
        spreadsheet_id,
        basic_sheet_title="ç‰©ä»¶åŸºæœ¬æƒ…å ±",
        master_sheet_title="ç‰©ä»¶ãƒã‚¹ã‚¿",
    )
    if pm_view_df is None or pm_view_df.empty:
        st.error("ç‰©ä»¶ãƒã‚¹ã‚¿ï¼ˆï¼‹åŸºæœ¬æƒ…å ±ï¼‰ãŒç©ºã§ã™ã€‚å…ˆã«ã‚¿ãƒ–ã€ç‰©ä»¶ãƒã‚¹ã‚¿ç®¡ç†ã€ã§ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
        return

    # ã€Œè‡ªç¤¾ã€ãƒ•ãƒ©ã‚°ä»¶æ•°ã®è¡¨ç¤ºï¼ˆå˜ãªã‚‹å‚è€ƒï¼‰
    col_flag = "è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥"
    if col_flag in pm_view_df.columns:
        flag_series = pm_view_df[col_flag].fillna("").astype(str).str.strip()
        cnt_jisha = (flag_series == "è‡ªç¤¾").sum()
        st.caption(f"ç‰©ä»¶ãƒã‚¹ã‚¿ç™»éŒ²ä»¶æ•°: {len(pm_view_df)} ä»¶ / è²¼ã‚Šç´™å¯¾è±¡ï¼ˆè‡ªç¤¾ï¼‰: {cnt_jisha} ä»¶")
    else:
        st.caption(f"ç‰©ä»¶ãƒã‚¹ã‚¿ç™»éŒ²ä»¶æ•°: {len(pm_view_df)} ä»¶")

    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é¸æŠ
    cal_names = list(editable_calendar_options.keys())
    default_cal = cal_names[0] if cal_names else None
    calendar_name = st.selectbox(
        "å¯¾è±¡ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼",
        cal_names,
        index=(cal_names.index(default_cal) if default_cal in cal_names else 0),
        key="notice_fax_calendar",
    )
    calendar_id = editable_calendar_options.get(calendar_name)

    # æœŸé–“æŒ‡å®š
    today = date.today()
    col_d1, col_d2 = st.columns(2)
    with col_d1:
        start_date = st.date_input("å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®é–‹å§‹æ—¥", value=today, key="notice_fax_start_date")
    with col_d2:
        end_date = st.date_input("å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã®çµ‚äº†æ—¥", value=today + timedelta(days=60), key="notice_fax_end_date")

    if start_date > end_date:
        st.error("é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ä»¥å‰ã®æ—¥ä»˜ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        return

    # ã‚¤ãƒ™ãƒ³ãƒˆå–å¾—ãƒœã‚¿ãƒ³
    fetch_btn = st.button("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰å¯¾è±¡ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã—ã€è²¼ã‚Šç´™å€™è£œã‚’ä½œæˆã™ã‚‹", type="primary")

    if fetch_btn:
        with st.spinner("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ä¸­..."):
            events = fetch_events_in_range(service, calendar_id, start_date, end_date)

        st.write(f"å–å¾—ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆä»¶æ•°: {len(events)} ä»¶")

        # ç‰©ä»¶ãƒã‚¹ã‚¿ã‚’ç®¡ç†ç•ªå·ã§å¼•ã‘ã‚‹ã‚ˆã†ã«
        pm_idx = pm_view_df.set_index("ç®¡ç†ç•ªå·")

        candidates: List[Dict[str, Any]] = []
        events_by_id: Dict[str, Dict[str, Any]] = {}

        for ev in events:
            desc = safe_get(ev, "description") or ""
            summary = safe_get(ev, "summary") or ""

            mgmt = extract_assetnum(desc) or extract_assetnum(summary)
            if not mgmt:
                continue
            mgmt_norm = mgmt.strip()

            if mgmt_norm not in pm_idx.index:
                continue

            pm_row = pm_idx.loc[mgmt_norm]

            # ç‰©ä»¶ãƒã‚¹ã‚¿å´ã®ãƒ•ãƒ©ã‚°ãŒã€Œè‡ªç¤¾ã€ã®ã‚‚ã®ã ã‘ã‚’å¯¾è±¡ã¨ã™ã‚‹
            flag_val = str(pm_row.get("è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥", "")).strip()
            if flag_val != "è‡ªç¤¾":
                continue

            start_dt = get_event_start_datetime(ev)
            start_date_val = start_dt.date() if start_dt else None
            date_str = start_date_val.strftime("%Y-%m-%d") if start_date_val else ""
            time_str = start_dt.strftime("%H:%M") if start_dt and "dateTime" in (ev.get("start") or {}) else ""

            work_type = extract_worktype(desc)
            if not work_type:
                work_type = "default"
            template_file = DEFAULT_TEMPLATE_MAP.get(work_type, DEFAULT_TEMPLATE_MAP.get("default"))

            candidates.append(
                {
                    "ä½œæˆ": True,
                    "event_id": ev.get("id") or "",
                    "ç®¡ç†ç•ªå·": mgmt_norm,
                    "ç‰©ä»¶å": _display_value(pm_row.get("ç‰©ä»¶å", "")),
                    "äºˆå®šæ—¥": date_str,
                    "äºˆå®šæ™‚é–“": time_str,
                    "ä½œæ¥­ã‚¿ã‚¤ãƒ—": work_type,
                    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«": template_file,
                    "è²¼ã‚Šç´™ãƒ•ãƒ©ã‚°": flag_val,
                    "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«": _display_value(summary),
                    "å‚™è€ƒ": _display_value(pm_row.get("å‚™è€ƒ", "")),
                }
            )

            ev_id = ev.get("id")
            if ev_id:
                events_by_id[ev_id] = ev

        if not candidates:
            st.info("è²¼ã‚Šç´™å¯¾è±¡ï¼ˆç‰©ä»¶ãƒã‚¹ã‚¿ã®ã€è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥ã€ãŒã€è‡ªç¤¾ã€ï¼‰ã¨ãªã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.session_state.pop("notice_fax_candidates_df", None)
            st.session_state.pop("notice_fax_events_by_id", None)
        else:
            cand_df = pd.DataFrame(candidates).fillna("")
            cand_df["ä½œæˆ"] = cand_df["ä½œæˆ"].astype(bool)

            st.session_state["notice_fax_candidates_df"] = cand_df
            st.session_state["notice_fax_events_by_id"] = events_by_id
            st.session_state["notice_fax_pm_view_df"] = pm_view_df

            st.success(f"è²¼ã‚Šç´™å€™è£œ {len(candidates)} ä»¶ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã“ã®ä¸‹ã§å†…å®¹ã‚’ç¢ºèªã—ã€ä½œæˆå¯¾è±¡ã‚’é¸æŠã§ãã¾ã™ã€‚")

    # ã“ã“ã‹ã‚‰ã¯æ—¢ã«å€™è£œãŒã‚ã‚‹å ´åˆã®è¡¨ç¤º
    cand_df: Optional[pd.DataFrame] = st.session_state.get("notice_fax_candidates_df")
    events_by_id: Dict[str, Dict[str, Any]] = st.session_state.get("notice_fax_events_by_id", {})
    pm_view_df = st.session_state.get("notice_fax_pm_view_df", pm_view_df)

    if cand_df is None or cand_df.empty:
        return

    st.markdown("### è²¼ã‚Šç´™ä½œæˆå€™è£œä¸€è¦§")
    st.caption("â€»ã€ä½œæˆã€ãƒã‚§ãƒƒã‚¯ãŒ ON ã®è¡Œã ã‘ãŒè²¼ã‚Šç´™ã¨ã—ã¦å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ OFF ã«ã—ã¦ãã ã•ã„ã€‚")

    display_cols = [
        "ä½œæˆ",
        "ç®¡ç†ç•ªå·",
        "ç‰©ä»¶å",
        "äºˆå®šæ—¥",
        "äºˆå®šæ™‚é–“",
        "ä½œæ¥­ã‚¿ã‚¤ãƒ—",
        "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«",
        "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«",
        "å‚™è€ƒ",
    ]

    for col in display_cols:
        if col not in cand_df.columns:
            cand_df[col] = True if col == "ä½œæˆ" else ""

    disp_df = cand_df[display_cols].copy()
    for col in disp_df.columns:
        if col == "ä½œæˆ":
            disp_df[col] = disp_df[col].astype(bool)
        else:
            disp_df[col] = (
                disp_df[col]
                .fillna("")
                .astype(str)
                .replace({"nan": "-", "NaN": "-", "None": "-"})
            )

    edit_df = st.data_editor(
        disp_df,
        num_rows="fixed",
        use_container_width=True,
        hide_index=True,
        column_config={
            "ä½œæˆ": st.column_config.CheckboxColumn("ä½œæˆ"),
            "ç®¡ç†ç•ªå·": st.column_config.TextColumn("ç®¡ç†ç•ªå·", disabled=True),
            "ç‰©ä»¶å": st.column_config.TextColumn("ç‰©ä»¶å", disabled=True),
            "äºˆå®šæ—¥": st.column_config.TextColumn("äºˆå®šæ—¥", disabled=True),
            "äºˆå®šæ™‚é–“": st.column_config.TextColumn("äºˆå®šæ™‚é–“", disabled=True),
            "ä½œæ¥­ã‚¿ã‚¤ãƒ—": st.column_config.TextColumn("ä½œæ¥­ã‚¿ã‚¤ãƒ—", disabled=True),
            "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«": st.column_config.TextColumn("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ•ã‚¡ã‚¤ãƒ«", disabled=True),
            "ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«": st.column_config.TextColumn("ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒˆãƒ«", disabled=True),
            "å‚™è€ƒ": st.column_config.TextColumn("å‚™è€ƒ", disabled=True),
        },
        key="notice_fax_editor",
    )

    cand_df["ä½œæˆ"] = edit_df["ä½œæˆ"].values
    st.session_state["notice_fax_candidates_df"] = cand_df

    generate_btn = st.button("âœ… é¸æŠã•ã‚ŒãŸè¡Œã®è²¼ã‚Šç´™ã‚’ä¸€æ‹¬ç”Ÿæˆã—ã€ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹", type="primary")

    if not generate_btn:
        return

    target_df = cand_df[cand_df["ä½œæˆ"] == True].copy()
    if target_df.empty:
        st.warning("ã€ä½œæˆã€ã«ãƒã‚§ãƒƒã‚¯ãŒå…¥ã£ã¦ã„ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    if not events_by_id:
        st.error("å†…éƒ¨ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†åº¦ã€è²¼ã‚Šç´™å€™è£œã‚’ä½œæˆã€ãƒœã‚¿ãƒ³ã‹ã‚‰ã‚„ã‚Šç›´ã—ã¦ãã ã•ã„ã€‚")
        return

    pm_idx = pm_view_df.set_index("ç®¡ç†ç•ªå·")

    outputs: List[tuple[str, bytes]] = []
    errors: List[str] = []

    with st.spinner("è²¼ã‚Šç´™ï¼ˆWordï¼‰ã‚’ç”Ÿæˆä¸­..."):
        for _, row in target_df.iterrows():
            event_id = row.get("event_id")
            mgmt = row.get("ç®¡ç†ç•ªå·")
            if not event_id or not mgmt:
                continue

            ev = events_by_id.get(event_id)
            if ev is None:
                continue

            if mgmt not in pm_idx.index:
                continue
            pm_row = pm_idx.loc[mgmt]

            desc = safe_get(ev, "description") or ""
            summary = safe_get(ev, "summary") or ""

            tags = extract_tags_from_description(desc or "")
            # description ã«ç®¡ç†ç•ªå·ã‚¿ã‚°ãŒå…¥ã£ã¦ã„ãªã„å ´åˆã‚‚ã‚ã‚‹ã®ã§è£œå®Œ
            if "ASSETNUM" not in tags and mgmt:
                tags["ASSETNUM"] = mgmt

            work_type = extract_worktype(desc)
            if not work_type:
                work_type = "default"
            template_file = DEFAULT_TEMPLATE_MAP.get(work_type, DEFAULT_TEMPLATE_MAP.get("default"))
            template_path = os.path.join("templates", template_file)

            start_dt = get_event_start_datetime(ev)
            when_str = ""
            if start_dt:
                d = start_dt.date()
                when_str = d.strftime("%Y-%m-%d")

            # NAME ã¯ç‰©ä»¶ãƒã‚¹ã‚¿ã®ç‰©ä»¶åã‚’å„ªå…ˆ
            name_for_doc = str(pm_row.get("ç‰©ä»¶å") or summary or mgmt or "").strip()
            replacements = build_replacements_from_event(ev, name_for_doc, tags)

            safe_title = _build_safe_title(when_str, mgmt, name_for_doc)

            try:
                out_name, content = generate_docx_from_template_like(
                    template_path,
                    replacements,
                    safe_title,
                )
                outputs.append((out_name, content))
            except Exception as e:
                errors.append(f"{mgmt}: {e}")

    if not outputs:
        st.error("è²¼ã‚Šç´™ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½®ã‚„æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        if errors:
            st.warning(f"ã‚¨ãƒ©ãƒ¼ä¾‹: {errors[0]}")
        return

    mem_zip = io.BytesIO()
    with zipfile.ZipFile(mem_zip, "w", zipfile.ZIP_DEFLATED) as zf:
        used_names = set()
        for fname, content in outputs:
            base_name = fname or "harigami.docx"
            name = base_name
            idx = 1
            while name in used_names:
                root, ext = os.path.splitext(base_name)
                name = f"{root}_{idx}{ext}"
                idx += 1
            used_names.add(name)
            zf.writestr(name, content)

    mem_zip.seek(0)
    zip_filename = f"harigami_{datetime.now().strftime('%Y%m%d')}.zip"

    st.download_button(
        "ğŸ“¦ è²¼ã‚Šç´™ZIPã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=mem_zip.getvalue(),
        file_name=zip_filename,
        mime="application/zip",
    )

    if errors:
        st.warning(f"ä¸€éƒ¨ã®è²¼ã‚Šç´™ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{len(errors)} ä»¶ï¼‰ã€‚å…ˆé ­ã®ã‚¨ãƒ©ãƒ¼: {errors[0]}")
