# tabs/tab6_property_master.py
from __future__ import annotations

from datetime import datetime
from typing import Optional, Any
from io import BytesIO

import pandas as pd
import streamlit as st


# ==========================
# åˆ—å®šç¾©
# ==========================

# ç‰©ä»¶ãƒã‚¹ã‚¿ï¼ˆç‚¹æ¤œæ¡ä»¶ãƒ»é€£çµ¡æ–¹æ³•ãªã©ï¼‰
MASTER_COLUMNS = [
    "ç®¡ç†ç•ªå·",
    "ç‚¹æ¤œå®Ÿæ–½æœˆ",
    "é€£çµ¡æœŸé™_æ—¥å‰",
    "é€£çµ¡æ–¹æ³•_é›»è©±1",
    "é€£çµ¡æ–¹æ³•_é›»è©±2",
    "é€£çµ¡æ–¹æ³•_FAX1",
    "é€£çµ¡æ–¹æ³•_FAX2",
    "é€£çµ¡æ–¹æ³•_ãƒ¡ãƒ¼ãƒ«1",
    "é€£çµ¡æ–¹æ³•_ãƒ¡ãƒ¼ãƒ«2",
    "é›»è©±ç•ªå·1",
    "é›»è©±ç•ªå·2",
    "FAXç•ªå·1",
    "FAXç•ªå·2",
    "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹1",
    "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹2",
    "é€£çµ¡å®›å1",
    "é€£çµ¡å®›å2",
    "OKæ›œæ—¥",
    "NGæ›œæ—¥",
    "OKæ™‚é–“å¸¯_é–‹å§‹",
    "OKæ™‚é–“å¸¯_çµ‚äº†",
    "NGæ™‚é–“å¸¯_é–‹å§‹",
    "NGæ™‚é–“å¸¯_çµ‚äº†",
    "è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥",
    "è²¼ã‚Šç´™ãƒ†ãƒ³ãƒ—ãƒ¬_ãƒ‰ãƒ©ã‚¤ãƒ–ID",
    "FAXãƒ†ãƒ³ãƒ—ãƒ¬ç¨®åˆ¥",
    "FAXãƒ†ãƒ³ãƒ—ãƒ¬_ãƒ‰ãƒ©ã‚¤ãƒ–ID",
    "ãƒ¡ãƒ¼ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬_ãƒ‰ãƒ©ã‚¤ãƒ–ID",
    "å‚™è€ƒ",
    "æ›´æ–°æ—¥æ™‚",
    "æœ€çµ‚æ›´æ–°è€…",
]

# ç‰©ä»¶åŸºæœ¬æƒ…å ±ï¼ˆExcel/CSV ã‹ã‚‰å–ã‚Šè¾¼ã‚€ï¼‰
BASIC_COLUMNS = [
    "ç®¡ç†ç•ªå·",
    "ç‰©ä»¶å",
    "ä½æ‰€",
    "çª“å£ä¼šç¤¾",
    "æ‹…å½“éƒ¨ç½²",
    "æ‹…å½“è€…å",
    "å¥‘ç´„ç¨®åˆ¥",
]


# ==========================
# å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼
# ==========================

def _normalize_df(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:
    """æŒ‡å®šåˆ—ã ã‘ã«æƒãˆã¦ã€æ–‡å­—åˆ— + strip ã«çµ±ä¸€"""
    df = df.copy() if df is not None else pd.DataFrame()
    for col in columns:
        if col not in df.columns:
            df[col] = ""
    df = df[columns].copy()
    if not df.empty:
        df = df.astype(str).apply(lambda col: col.str.strip())
    return df


# ==========================
# Sheets ãƒ˜ãƒ«ãƒ‘ãƒ¼
# ==========================

def ensure_sheet_and_headers(
    sheets_service: Any,
    spreadsheet_id: str,
    sheet_title: str,
    headers: list[str],
) -> None:
    """
    æŒ‡å®šã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå†…ã«ã‚·ãƒ¼ãƒˆã‚’ä½œæˆã—ã€
    1è¡Œç›®ã«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚»ãƒƒãƒˆã™ã‚‹ï¼ˆãªã‘ã‚Œã°ï¼‰ã€‚
    """
    if not sheets_service or not spreadsheet_id:
        return

    # ã‚·ãƒ¼ãƒˆä¸€è¦§å–å¾—
    meta = sheets_service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
    sheets = meta.get("sheets", [])
    existing_titles = {s["properties"]["title"] for s in sheets}

    # ã‚·ãƒ¼ãƒˆãŒãªã‘ã‚Œã°è¿½åŠ 
    if sheet_title not in existing_titles:
        body = {
            "requests": [
                {
                    "addSheet": {
                        "properties": {
                            "title": sheet_title,
                        }
                    }
                }
            ]
        }
        sheets_service.spreadsheets().batchUpdate(
            spreadsheetId=spreadsheet_id,
            body=body,
        ).execute()

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ç¢ºèª
    range_header = f"{sheet_title}!1:1"
    result = sheets_service.spreadsheets().values().get(
        spreadsheetId=spreadsheet_id,
        range=range_header,
    ).execute()
    values = result.get("values", [])

    need_update_header = False
    if not values:
        need_update_header = True
    else:
        current_header = values[0]
        if current_header != headers:
            need_update_header = True

    if need_update_header:
        body = {"values": [headers]}
        sheets_service.spreadsheets().values().update(
            spreadsheetId=spreadsheet_id,
            range=f"{sheet_title}!A1",
            valueInputOption="RAW",
            body=body,
        ).execute()


def create_property_master_spreadsheet(
    sheets_service: Any,
    user_email: Optional[str] = None,
) -> str:
    """
    ç‰©ä»¶åŸºæœ¬æƒ…å ± / ç‰©ä»¶ãƒã‚¹ã‚¿ ã®2ã‚·ãƒ¼ãƒˆã‚’æŒã¤ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ–°è¦ä½œæˆã—ã€
    ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã¦ Spreadsheet ID ã‚’è¿”ã™ã€‚
    """
    if not sheets_service:
        raise RuntimeError("Sheets service is not initialized")

    title_suffix = user_email or "property_master"
    body = {
        "properties": {
            "title": f"ç‰©ä»¶ãƒã‚¹ã‚¿_{title_suffix}",
        },
        "sheets": [
            {"properties": {"title": "ç‰©ä»¶åŸºæœ¬æƒ…å ±"}},
            {"properties": {"title": "ç‰©ä»¶ãƒã‚¹ã‚¿"}},
        ],
    }
    resp = sheets_service.spreadsheets().create(body=body).execute()
    spreadsheet_id = resp["spreadsheetId"]

    # ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿
    ensure_sheet_and_headers(sheets_service, spreadsheet_id, "ç‰©ä»¶åŸºæœ¬æƒ…å ±", BASIC_COLUMNS)
    ensure_sheet_and_headers(sheets_service, spreadsheet_id, "ç‰©ä»¶ãƒã‚¹ã‚¿", MASTER_COLUMNS)

    return spreadsheet_id


def load_sheet_as_df(
    sheets_service: Any,
    spreadsheet_id: str,
    sheet_title: str,
    columns: list[str],
) -> pd.DataFrame:
    """
    A1 ã‹ã‚‰ã®å†…å®¹ã‚’ DataFrame ã¨ã—ã¦å–å¾—ã—ã€æŒ‡å®šåˆ—ã«æƒãˆã¦è¿”ã™ã€‚
    """
    if not sheets_service or not spreadsheet_id:
        return pd.DataFrame(columns=columns)

    range_name = f"{sheet_title}!A1:ZZ"
    try:
        result = sheets_service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=range_name,
        ).execute()
    except Exception as e:
        st.error(f"{sheet_title} ã‚·ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame(columns=columns)

    values = result.get("values", [])
    if not values:
        return pd.DataFrame(columns=columns)

    header = values[0]
    rows = values[1:] if len(values) > 1 else []

    df = pd.DataFrame(rows, columns=header)
    df = df.astype(str).apply(lambda col: col.str.strip())
    # è¶³ã‚Šãªã„åˆ—è£œå®Œ
    for col in columns:
        if col not in df.columns:
            df[col] = ""
    return df[columns].copy()


def save_df_to_sheet(
    sheets_service: Any,
    spreadsheet_id: str,
    sheet_title: str,
    df: pd.DataFrame,
    columns: list[str],
) -> None:
    """æŒ‡å®š DataFrame ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼è¾¼ã¿ã§ã‚·ãƒ¼ãƒˆã«ã¾ã‚‹ã”ã¨æ›¸ãæˆ»ã™ã€‚"""
    if not sheets_service or not spreadsheet_id:
        return

    df_to_save = _normalize_df(df, columns)
    values = [columns] + df_to_save.values.tolist()

    try:
        # ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚¯ãƒªã‚¢
        sheets_service.spreadsheets().values().clear(
            spreadsheetId=spreadsheet_id,
            range=sheet_title,
        ).execute()

        body = {"values": values}
        sheets_service.spreadsheets().values().update(
            spreadsheetId=spreadsheet_id,
            range=f"{sheet_title}!A1",
            valueInputOption="RAW",
            body=body,
        ).execute()
    except Exception as e:
        st.error(f"{sheet_title} ã‚·ãƒ¼ãƒˆã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise


# ==========================
# ç‰©ä»¶åŸºæœ¬æƒ…å ±ï¼šExcel/CSV èª­ã¿è¾¼ã¿ & å·®åˆ†
# ==========================

def load_basic_info_from_uploaded(uploaded_file) -> pd.DataFrame:
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ Excel/CSV ã‹ã‚‰ç‰©ä»¶åŸºæœ¬æƒ…å ± DataFrame ã‚’ä½œæˆã€‚
    - Excel: ãã®ã¾ã¾ read_excel
    - CSV : ã¾ãš UTF-8 / UTF-8-SIG ã‚’è©¦ã—ã€ãƒ€ãƒ¡ãªã‚‰ CP932(Shift_JIS) ã§å†ãƒˆãƒ©ã‚¤
    """
    if uploaded_file is None:
        return pd.DataFrame(columns=BASIC_COLUMNS)

    name = uploaded_file.name.lower()

    # --- Excel ã®å ´åˆ ---
    if name.endswith(".xlsx") or name.endswith(".xls"):
        df = pd.read_excel(uploaded_file, dtype=str)
        df = df.astype(str).apply(lambda col: col.str.strip())
        return _normalize_df(df, BASIC_COLUMNS)

    # --- CSV ã®å ´åˆ ---
    # ä¸€åº¦ãƒã‚¤ãƒˆåˆ—ã¨ã—ã¦èª­ã¿è¾¼ã¿ã€è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ãƒˆãƒ©ã‚¤ã™ã‚‹
    raw_bytes = uploaded_file.read()

    # ä»¥é™ã€ã“ã®é–¢æ•°ã®ä¸­ã ã‘ã§ raw_bytes ã‚’ä½¿ã„åˆ‡ã‚‹å‰æ
    encodings_to_try = ["utf-8", "utf-8-sig", "cp932"]

    last_err: Optional[Exception] = None
    for enc in encodings_to_try:
        try:
            df = pd.read_csv(BytesIO(raw_bytes), dtype=str, encoding=enc)
            df = df.astype(str).apply(lambda col: col.str.strip())
            return _normalize_df(df, BASIC_COLUMNS)
        except UnicodeDecodeError as e:
            last_err = e
            continue
        except Exception as e:
            last_err = e
            continue

    st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ï¼ˆæœ€å¾Œã®ã‚¨ãƒ©ãƒ¼: {last_err}ï¼‰")
    return pd.DataFrame(columns=BASIC_COLUMNS)


def diff_basic_info(current_df: pd.DataFrame, new_df: pd.DataFrame):
    """
    current_df: ç¾åœ¨ã‚·ãƒ¼ãƒˆã«å…¥ã£ã¦ã„ã‚‹åŸºæœ¬æƒ…å ±
    new_df    : æ–°ã—ãã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ Excel/CSV ã‚’èª­ã¿è¾¼ã‚“ã åŸºæœ¬æƒ…å ±

    æˆ»ã‚Šå€¤:
      - new_rows     : æ–°è¦è¿½åŠ è¡Œ
      - updated_rows : æ›´æ–°è¡Œï¼ˆæ–°ã—ã„å€¤ã€‚æ—§å€¤ã¯ *_æ—§ åˆ—ã§æŒã¤ï¼‰
      - deleted_rows : å‰Šé™¤å€™è£œè¡Œ
    """
    cur = _normalize_df(current_df, BASIC_COLUMNS)
    new = _normalize_df(new_df, BASIC_COLUMNS)

    cur_ids = set(cur["ç®¡ç†ç•ªå·"])
    new_ids = set(new["ç®¡ç†ç•ªå·"])

    new_only_ids = new_ids - cur_ids
    deleted_ids = cur_ids - new_ids
    common_ids = cur_ids & new_ids

    new_rows = new[new["ç®¡ç†ç•ªå·"].isin(new_only_ids)].copy()
    deleted_rows = cur[cur["ç®¡ç†ç•ªå·"].isin(deleted_ids)].copy()

    cur_common = cur[cur["ç®¡ç†ç•ªå·"].isin(common_ids)].set_index("ç®¡ç†ç•ªå·")
    new_common = new[new["ç®¡ç†ç•ªå·"].isin(common_ids)].set_index("ç®¡ç†ç•ªå·")

    changed_ids = []
    for mid in common_ids:
        if not cur_common.loc[mid].equals(new_common.loc[mid]):
            changed_ids.append(mid)

    updated_cur = cur_common.loc[changed_ids].reset_index()
    updated_new = new_common.loc[changed_ids].reset_index()

    updated_rows = updated_new.copy()
    for col in BASIC_COLUMNS:
        if col == "ç®¡ç†ç•ªå·":
            continue
        updated_rows[f"{col}_æ—§"] = updated_cur[col].values

    return new_rows, updated_rows, deleted_rows


# ==========================
# ãƒãƒ¼ã‚¸å‡¦ç†
# ==========================

def merge_master_and_basic(master_df: pd.DataFrame, basic_df: pd.DataFrame) -> pd.DataFrame:
    """ç®¡ç†ç•ªå·ã§ç‰©ä»¶ãƒã‚¹ã‚¿ã¨åŸºæœ¬æƒ…å ±ã‚’ãƒãƒ¼ã‚¸ã—ã¦è¡¨ç¤ºç”¨ DataFrame ã«ã™ã‚‹ã€‚"""
    master_df = _normalize_df(master_df, MASTER_COLUMNS)
    basic_df = _normalize_df(basic_df, BASIC_COLUMNS)

    if master_df.empty:
        merged = basic_df.copy()
        for col in MASTER_COLUMNS:
            if col not in merged.columns:
                merged[col] = ""
        return merged

    merged = master_df.merge(
        basic_df,
        on="ç®¡ç†ç•ªå·",
        how="left",
        suffixes=("", "_åŸºæœ¬"),
    )

    display_cols = (
        ["ç®¡ç†ç•ªå·", "ç‰©ä»¶å", "ä½æ‰€", "çª“å£ä¼šç¤¾", "æ‹…å½“éƒ¨ç½²", "æ‹…å½“è€…å", "å¥‘ç´„ç¨®åˆ¥"]
        + [col for col in MASTER_COLUMNS if col != "ç®¡ç†ç•ªå·"]
    )
    display_cols = [c for c in display_cols if c in merged.columns]
    return merged[display_cols]


# ==========================
# ãƒ¡ã‚¤ãƒ³ UI
# ==========================

def render_tab6_property_master(
    sheets_service: Any,
    default_spreadsheet_id: str = "",
    basic_sheet_title: str = "ç‰©ä»¶åŸºæœ¬æƒ…å ±",
    master_sheet_title: str = "ç‰©ä»¶ãƒã‚¹ã‚¿",
    current_user_email: Optional[str] = None,
):
    """
    ç‰©ä»¶ãƒã‚¹ã‚¿ç®¡ç†ã‚¿ãƒ–
    - ç‰©ä»¶åŸºæœ¬æƒ…å ± / ç‰©ä»¶ãƒã‚¹ã‚¿ ã‚’åŒä¸€ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ¥ã‚·ãƒ¼ãƒˆã¨ã—ã¦ç®¡ç†
    - Excel/CSV ã‹ã‚‰åŸºæœ¬æƒ…å ±ã‚’å–ã‚Šè¾¼ã¿ã€å·®åˆ†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ ã‚·ãƒ¼ãƒˆåæ˜ 
    - ç‰©ä»¶ãƒã‚¹ã‚¿ã¯ Data Editor ã§ç·¨é›† â†’ ã‚·ãƒ¼ãƒˆä¿å­˜
    """
    st.subheader("ç‰©ä»¶ãƒã‚¹ã‚¿ç®¡ç†")

    # ------------------------------
    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š & æ–°è¦ä½œæˆ
    # ------------------------------
    with st.expander("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆè¨­å®š", expanded=True):
        col1, col2 = st.columns([3, 2])

        # 1) å…ˆã«ã€Œæ–°è¦ä½œæˆãƒœã‚¿ãƒ³ã€ã‚’å‡¦ç†ã—ã€å¿…è¦ãªã‚‰ session_state ã« ID ã‚’ã‚»ãƒƒãƒˆ
        with col2:
            st.write("ã€€")
            if st.button("ğŸ†• æ–°è¦ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä½œæˆ", use_container_width=True):
                if not sheets_service:
                    st.error("Sheets API ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                else:
                    try:
                        new_id = create_property_master_spreadsheet(
                            sheets_service,
                            user_email=current_user_email,
                        )
                        st.session_state["pm_spreadsheet_id"] = new_id
                        st.success(f"æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚\nID: {new_id}")
                        st.info("å¿…è¦ã§ã‚ã‚Œã°ã€ã“ã®IDã‚’ secrets.toml ã® PROPERTY_MASTER_SHEET_ID ã«ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ–°è¦ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # 2) session_state ã«å…¥ã£ã¦ã„ã‚‹å€¤ or default ã‹ã‚‰ text_input ã‚’è¡¨ç¤º
        default_id = st.session_state.get("pm_spreadsheet_id", default_spreadsheet_id)
        with col1:
            spreadsheet_id = st.text_input(
                "ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆID",
                value=default_id,
                key="pm_spreadsheet_id",
                help="ç‰©ä»¶åŸºæœ¬æƒ…å ± / ç‰©ä»¶ãƒã‚¹ã‚¿ ã‚’ä¿å­˜ã™ã‚‹ Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã® ID ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
            )

        col3, col4 = st.columns(2)
        with col3:
            basic_title = st.text_input(
                "ç‰©ä»¶åŸºæœ¬æƒ…å ±ã‚·ãƒ¼ãƒˆå",
                value=st.session_state.get("pm_basic_sheet_title", basic_sheet_title),
                key="pm_basic_sheet_title",
            )
        with col4:
            master_title = st.text_input(
                "ç‰©ä»¶ãƒã‚¹ã‚¿ã‚·ãƒ¼ãƒˆå",
                value=st.session_state.get("pm_master_sheet_title", master_sheet_title),
                key="pm_master_sheet_title",
            )

        load_btn = st.button("ç‰©ä»¶ãƒã‚¹ã‚¿ ï¼‹ åŸºæœ¬æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€", type="primary")

    # ------------------------------
    # ç‰©ä»¶åŸºæœ¬æƒ…å ±ï¼šExcel/CSV â†’ ã‚·ãƒ¼ãƒˆ
    # ------------------------------
    with st.expander("ç‰©ä»¶åŸºæœ¬æƒ…å ±ï¼ˆExcel/CSV ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰", expanded=False):
        st.caption("â€» åŸæœ¬ã¨ãªã‚‹ Excel/CSV ã‹ã‚‰ã€ç‰©ä»¶åŸºæœ¬æƒ…å ±ã€ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ã—ã¾ã™ã€‚é€šå¸¸ã¯æœ€åˆã«1å›è¡Œã„ã€å¤‰æ›´ãŒã‚ã£ãŸã¨ãã®ã¿å†å®Ÿè¡Œã—ã¾ã™ã€‚")

        uploaded_basic = st.file_uploader(
            "ç‰©ä»¶åŸºæœ¬æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆExcel or CSVï¼‰",
            type=["xlsx", "xls", "csv"],
            key="pm_basic_file_upload",
        )

        col_u1, col_u2 = st.columns(2)
        with col_u1:
            preview_diff_btn = st.button("å·®åˆ†ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="pm_preview_diff")
        with col_u2:
            apply_diff_btn = st.button("å·®åˆ†ã‚’ã‚·ãƒ¼ãƒˆã«åæ˜ ", key="pm_apply_diff")

        # å·®åˆ†ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        if preview_diff_btn:
            if not spreadsheet_id:
                st.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å…ˆã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            elif not sheets_service:
                st.error("Sheets API ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif uploaded_basic is None:
                st.error("Excel/CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    ensure_sheet_and_headers(
                        sheets_service,
                        spreadsheet_id,
                        basic_title,
                        BASIC_COLUMNS,
                    )
                    current_df = load_sheet_as_df(
                        sheets_service,
                        spreadsheet_id,
                        basic_title,
                        BASIC_COLUMNS,
                    )
                    new_df = load_basic_info_from_uploaded(uploaded_basic)

                    new_rows, updated_rows, deleted_rows = diff_basic_info(current_df, new_df)

                    st.session_state["pm_basic_uploaded_df"] = new_df
                    st.session_state["pm_basic_new_rows"] = new_rows
                    st.session_state["pm_basic_updated_rows"] = updated_rows
                    st.session_state["pm_basic_deleted_rows"] = deleted_rows

                    st.success("å·®åˆ†ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚")
                except Exception as e:
                    st.error(f"å·®åˆ†è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        # å·®åˆ†è¡¨ç¤º
        new_rows = st.session_state.get("pm_basic_new_rows")
        updated_rows = st.session_state.get("pm_basic_updated_rows")
        deleted_rows = st.session_state.get("pm_basic_deleted_rows")

        if isinstance(new_rows, pd.DataFrame):
            st.write(f"âœ… æ–°è¦è¿½åŠ å€™è£œ: {len(new_rows)} ä»¶")
            if len(new_rows) > 0:
                st.dataframe(new_rows, use_container_width=True, height=200)

        if isinstance(updated_rows, pd.DataFrame):
            st.write(f"âœ… æ›´æ–°å€™è£œ: {len(updated_rows)} ä»¶")
            if len(updated_rows) > 0:
                st.dataframe(updated_rows, use_container_width=True, height=200)

        if isinstance(deleted_rows, pd.DataFrame):
            st.write(f"âš ï¸ å‰Šé™¤å€™è£œ: {len(deleted_rows)} ä»¶ï¼ˆâ€»åæ˜ æ™‚ã¯æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã§ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚’ç½®ãæ›ãˆã¾ã™ï¼‰")
            if len(deleted_rows) > 0:
                st.dataframe(deleted_rows, use_container_width=True, height=200)

        # å·®åˆ†åæ˜ ï¼ˆå®Ÿéš›ã«ã¯ã€Œæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã§ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚’ç½®ãæ›ãˆã€ï¼‰
        if apply_diff_btn:
            new_df = st.session_state.get("pm_basic_uploaded_df")
            if not spreadsheet_id:
                st.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å…ˆã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            elif not sheets_service:
                st.error("Sheets API ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            elif new_df is None:
                st.error("å·®åˆ†ãŒè¨ˆç®—ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«ã€å·®åˆ†ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    ensure_sheet_and_headers(
                        sheets_service,
                        spreadsheet_id,
                        basic_title,
                        BASIC_COLUMNS,
                    )
                    save_df_to_sheet(
                        sheets_service,
                        spreadsheet_id,
                        basic_title,
                        new_df,
                        BASIC_COLUMNS,
                    )
                    st.success("ç‰©ä»¶åŸºæœ¬æƒ…å ±ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚ï¼ˆæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã§å…¨è¡Œã‚’ç½®ãæ›ãˆã¦ã„ã¾ã™ï¼‰")

                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸Šã®åŸºæœ¬æƒ…å ±ã‚‚æ›´æ–°
                    st.session_state["pm_basic_df"] = _normalize_df(new_df, BASIC_COLUMNS)
                except Exception as e:
                    st.error(f"ç‰©ä»¶åŸºæœ¬æƒ…å ±ã‚·ãƒ¼ãƒˆã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # ------------------------------
    # ç‰©ä»¶ãƒã‚¹ã‚¿ï¼‹åŸºæœ¬æƒ…å ± èª­ã¿è¾¼ã¿
    # ------------------------------
    if load_btn:
        if not spreadsheet_id:
            st.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        elif not sheets_service:
            st.error("Sheets API ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            try:
                ensure_sheet_and_headers(
                    sheets_service,
                    spreadsheet_id,
                    basic_title,
                    BASIC_COLUMNS,
                )
                ensure_sheet_and_headers(
                    sheets_service,
                    spreadsheet_id,
                    master_title,
                    MASTER_COLUMNS,
                )

                basic_df = load_sheet_as_df(
                    sheets_service,
                    spreadsheet_id,
                    basic_title,
                    BASIC_COLUMNS,
                )
                master_df = load_sheet_as_df(
                    sheets_service,
                    spreadsheet_id,
                    master_title,
                    MASTER_COLUMNS,
                )

                merged_df = merge_master_and_basic(master_df, basic_df)

                st.session_state["pm_basic_df"] = basic_df
                st.session_state["pm_master_df"] = master_df
                st.session_state["pm_merged_df"] = merged_df
                st.success("ç‰©ä»¶ãƒã‚¹ã‚¿ ï¼‹ åŸºæœ¬æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
            except Exception as e:
                st.error(f"ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    merged_df: Optional[pd.DataFrame] = st.session_state.get("pm_merged_df")

    if merged_df is None or merged_df.empty:
        st.info("ä¸Šéƒ¨ã®ã€ç‰©ä»¶ãƒã‚¹ã‚¿ ï¼‹ åŸºæœ¬æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ã€ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚")
        return

    # ------------------------------
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    # ------------------------------
    with st.expander("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            keyword = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆç®¡ç†ç•ªå· / ç‰©ä»¶å / ä½æ‰€ãªã©ï¼‰", key="pm_keyword")
        with col2:
            only_has_master = st.checkbox(
                "ç‰©ä»¶ãƒã‚¹ã‚¿ã«ç™»éŒ²ãŒã‚ã‚‹ç®¡ç†ç•ªå·ã®ã¿è¡¨ç¤º",
                value=False,
                key="pm_only_has_master",
            )

    df_view = merged_df.copy()

    if keyword:
        kw = keyword.strip()
        mask = pd.Series(False, index=df_view.index)
        for col in ["ç®¡ç†ç•ªå·", "ç‰©ä»¶å", "ä½æ‰€", "çª“å£ä¼šç¤¾", "æ‹…å½“éƒ¨ç½²", "æ‹…å½“è€…å"]:
            if col in df_view.columns:
                mask |= df_view[col].astype(str).str.contains(kw, case=False, na=False)
        df_view = df_view[mask]

    if only_has_master:
        master_cols_for_check = [
            "ç‚¹æ¤œå®Ÿæ–½æœˆ",
            "é€£çµ¡æœŸé™_æ—¥å‰",
            "é€£çµ¡æ–¹æ³•_é›»è©±1",
            "é€£çµ¡æ–¹æ³•_é›»è©±2",
            "é€£çµ¡æ–¹æ³•_FAX1",
            "é€£çµ¡æ–¹æ³•_FAX2",
            "é€£çµ¡æ–¹æ³•_ãƒ¡ãƒ¼ãƒ«1",
            "é€£çµ¡æ–¹æ³•_ãƒ¡ãƒ¼ãƒ«2",
        ]
        has_any = pd.Series(False, index=df_view.index)
        for col in master_cols_for_check:
            if col in df_view.columns:
                has_any |= df_view[col].astype(str).str.strip() != ""
        df_view = df_view[has_any]

    # å‰Šé™¤ç”¨ã®ã€Œé¸æŠã€åˆ—è¿½åŠ 
    if "é¸æŠ" not in df_view.columns:
        df_view.insert(0, "é¸æŠ", False)

    st.caption("â€» ç‰©ä»¶åŸºæœ¬æƒ…å ±ã¯ã€ç‰©ä»¶åŸºæœ¬æƒ…å ±ã€ã‚·ãƒ¼ãƒˆã€ç‰©ä»¶ãƒã‚¹ã‚¿ã¯ã€ç‰©ä»¶ãƒã‚¹ã‚¿ã€ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚åŸºæœ¬æƒ…å ±ã‚’ç·¨é›†ã—ãŸã„å ´åˆã¯ã€Excel/CSV ã‚’æ›´æ–°ã—ã¦å†ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")

    edited_df = st.data_editor(
        df_view,
        num_rows="dynamic",
        key="pm_editor",
        use_container_width=True,
        hide_index=True,
    )

    col_a, col_b, col_c = st.columns(3)
    with col_a:
        if st.button("é¸æŠè¡Œã‚’å‰Šé™¤"):
            if "é¸æŠ" in edited_df.columns:
                edited_df = edited_df[~edited_df["é¸æŠ"]].copy()
                st.session_state["pm_merged_df"] = edited_df.drop(columns=["é¸æŠ"])
                st.success("é¸æŠã•ã‚ŒãŸè¡Œã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚ï¼ˆä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ç‰©ä»¶ãƒã‚¹ã‚¿ã€ã‚·ãƒ¼ãƒˆã«åæ˜ ã•ã‚Œã¾ã™ï¼‰")
            else:
                st.warning("é¸æŠåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    with col_b:
        if st.button("æ–°è¦è¡Œã‚’è¿½åŠ "):
            new_row = {col: "" for col in edited_df.columns}
            new_row["é¸æŠ"] = False
            edited_df = pd.concat([edited_df, pd.DataFrame([new_row])], ignore_index=True)
            st.session_state["pm_merged_df"] = edited_df.drop(columns=["é¸æŠ"])
            st.success("ç©ºã®è¡Œã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚ï¼ˆä¿å­˜ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ç‰©ä»¶ãƒã‚¹ã‚¿ã€ã‚·ãƒ¼ãƒˆã«åæ˜ ã•ã‚Œã¾ã™ï¼‰")

    with col_c:
        save_btn = st.button("ã€ç‰©ä»¶ãƒã‚¹ã‚¿ã€ã‚·ãƒ¼ãƒˆã«ä¿å­˜", type="primary")

    # ------------------------------
    # ç‰©ä»¶ãƒã‚¹ã‚¿ã‚·ãƒ¼ãƒˆã¸ã®ä¿å­˜
    # ------------------------------
    if save_btn:
        if not spreadsheet_id:
            st.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒæœªå…¥åŠ›ã§ã™ã€‚")
            return
        if not sheets_service:
            st.error("Sheets API ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        save_df = edited_df.drop(columns=["é¸æŠ"]) if "é¸æŠ" in edited_df.columns else edited_df.copy()

        # ç‰©ä»¶ãƒã‚¹ã‚¿ç”¨ã®åˆ—ã ã‘æŠ½å‡º
        master_only = _normalize_df(save_df, MASTER_COLUMNS)

        # æ›´æ–°æ—¥æ™‚ãƒ»æœ€çµ‚æ›´æ–°è€…
        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if "æ›´æ–°æ—¥æ™‚" in master_only.columns:
            master_only["æ›´æ–°æ—¥æ™‚"] = now_str
        if "æœ€çµ‚æ›´æ–°è€…" in master_only.columns and current_user_email:
            master_only["æœ€çµ‚æ›´æ–°è€…"] = current_user_email

        try:
            ensure_sheet_and_headers(
                sheets_service,
                spreadsheet_id,
                master_title,
                MASTER_COLUMNS,
            )
            save_df_to_sheet(
                sheets_service,
                spreadsheet_id,
                master_title,
                master_only,
                MASTER_COLUMNS,
            )
            st.session_state["pm_master_df"] = master_only

            # æœ€æ–°ã®åŸºæœ¬æƒ…å ±ã¨å†ãƒãƒ¼ã‚¸
            basic_df = st.session_state.get("pm_basic_df") or load_sheet_as_df(
                sheets_service,
                spreadsheet_id,
                basic_title,
                BASIC_COLUMNS,
            )
            merged_df_latest = merge_master_and_basic(master_only, basic_df)
            st.session_state["pm_merged_df"] = merged_df_latest

            st.success("ã€ç‰©ä»¶ãƒã‚¹ã‚¿ã€ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ã¯ save_df_to_sheet / ensure å†…ã§è¡¨ç¤ºæ¸ˆã¿
            pass
